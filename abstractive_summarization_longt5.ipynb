{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666b936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all matra thiche pugcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d4c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max checkpoint path: ./results/checkpoint-80000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Path to the main directory containing checkpoints\n",
    "base_dir = \"results\"\n",
    "\n",
    "# List all folders in the directory\n",
    "folders = os.listdir(base_dir)\n",
    "\n",
    "# Filter for checkpoint folders and extract their numbers\n",
    "checkpoints = [\n",
    "    (folder, int(re.search(r\"checkpoint-(\\d+)\", folder).group(1)))\n",
    "    for folder in folders\n",
    "    if re.match(r\"checkpoint-\\d+\", folder)\n",
    "]\n",
    "\n",
    "# Get the folder with the highest checkpoint number\n",
    "max_checkpoint = max(checkpoints, key=lambda x: x[1])[0]\n",
    "\n",
    "# Full path to the checkpoint directory\n",
    "checkpoint_path = \"./results/\" + max_checkpoint\n",
    "\n",
    "# Output\n",
    "print(\"Max checkpoint path:\", checkpoint_path)\n",
    "# checkpoint_path = \"./results/checkpoint-41000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901a3763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.41.1 datasets==2.18.0 evaluate==0.4.1 torch==2.3.0 accelerate==0.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335148c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c1e109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . \n",
      " it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models\n",
      "Summary: additive models play an important role in semiparametric statistics . \n",
      " this paper gives learning rates for regularized kernel based methods for additive models . \n",
      " these learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the gaussian radial basis function kernel , provided the assumption of an additive model is valid . \n",
      " additionally , a concrete example is presented to show that a gaussian function depending only on one variable lies in a reproducing kernel hilbert space generated by an additive gaussian kernel , but does not belong to the reproducing kernel hilbert space generated by the multivariate gaussian kernel of the same variance .    * \n",
      " key words and phrases . * additive model , kernel , quantile regression , semiparametric , rate of convergence , support vector machine .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load arXiv summarization dataset\n",
    "dataset = load_dataset(\"ccdv/arxiv-summarization\")\n",
    "# dataset = dataset.select(range(1000))   # remove later\n",
    "sample = dataset[\"train\"][0]\n",
    "print(\"Article:\", sample[\"article\"][:500])\n",
    "print(\"Summary:\", sample[\"abstract\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3818c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from transformers import LongT5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# model_name = \"google/long-t5-tglobal-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = LongT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "# model.config.use_cache = False\n",
    "# model.gradient_checkpointing_enable() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b272b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongT5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = LongT5ForConditionalGeneration.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    local_files_only=True,\n",
    "    ignore_mismatched_sizes=True  # Optional: avoid shape mismatch crashes\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.gradient_checkpointing_enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddd5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(batch):\n",
    "    inputs = [\"summarize: \" + doc for doc in batch[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=4096, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch[\"abstract\"], max_length=256, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65810c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset has a 'train' split\n",
    "# tokenized_dataset = dataset[\"train\"].map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     remove_columns=[\"article\", \"abstract\"]\n",
    "# )\n",
    "\n",
    "# tokenized_dataset.save_to_disk(\"tokenized_dataset\")\n",
    "from datasets import load_from_disk\n",
    "tokenized_dataset = load_from_disk(\"tokenized_dataset\")\n",
    "\n",
    "# Then perform train-test split on the tokenized dataset\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "# 53 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21c8d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    accumulated_fmeasures = {\n",
    "        'rouge1': 0.0,\n",
    "        'rouge2': 0.0,\n",
    "        'rougeL': 0.0, \n",
    "    }\n",
    "    num_samples = 0\n",
    "\n",
    "    for pred_text, ref_text in zip(decoded_preds, decoded_labels):\n",
    "        scores = scorer.score(ref_text, pred_text)\n",
    "\n",
    "        for key in accumulated_fmeasures:\n",
    "            if key in scores:\n",
    "                accumulated_fmeasures[key] += scores[key].fmeasure\n",
    "        num_samples += 1\n",
    "\n",
    "    average_metrics = {}\n",
    "    if num_samples > 0:\n",
    "        for key, total_fmeasure in accumulated_fmeasures.items():\n",
    "            average_metrics[key] = (total_fmeasure / num_samples) * 100\n",
    "\n",
    "    return average_metrics\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, label_pad_token_id=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fead318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n",
      "NVIDIA GeForce RTX 3060\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0)) \n",
    "print(torch.backends.cudnn.version()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2680d0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Allocated:\", torch.cuda.memory_allocated() / 1024**3, \"GB\")\n",
    "        print(\"Cached:   \", torch.cuda.memory_reserved() / 1024**3, \"GB\")\n",
    "    else:\n",
    "        print(\"CUDA not available.\")\n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "831788b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "import os\n",
    "\n",
    "# Make sure results directory exists and is writable\n",
    "os.makedirs(\"./results\", exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    # eval_steps=5000,                      # Reduce frequency if not needed\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,                      # Keep it if you want frequent saves\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=False,         # OPTIONAL: Turn off to simplify\n",
    "    metric_for_best_model=\"rougeL\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    eval_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    "    # fp16=torch.cuda.is_available(),\n",
    "    fp16=False,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_grad_norm=1.0,\n",
    "    disable_tqdm=False,                   # Enable tqdm to check live logs\n",
    "    report_to=[],                         # Avoid WandB etc.\n",
    "    save_safetensors=True,                # âœ… Save in safer format\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2f9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.empty_cache()\n",
    "# from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     eval_steps=1000,\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=1000, \n",
    "#     save_total_limit=2,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"rougeL\",\n",
    "#     greater_is_better=True,\n",
    "#     learning_rate=3e-5,\n",
    "#     per_device_train_batch_size=1,\n",
    "#     per_device_eval_batch_size=1,\n",
    "#     eval_accumulation_steps=4, \n",
    "#     num_train_epochs=1,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=200,\n",
    "\n",
    "#     fp16=torch.cuda.is_available(),\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     max_grad_norm=1.0,\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e89a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import torch\n",
    "\n",
    "class ClipNanGradientsCallback(TrainerCallback):    \n",
    "    def on_step_end(self, args, state, control, model=None, **kwargs):\n",
    "        if model is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eca455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=None,\n",
    "    callbacks=[ClipNanGradientsCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66df9c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n",
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\trainer.py:3017: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "  0%|          | 0/91366 [00:00<?, ?it/s]c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\trainer.py:2758: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n",
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 80200/91366 [09:15<8:31:54,  2.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6468, 'grad_norm': 1.8130735158920288, 'learning_rate': 1.222117636757656e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 80400/91366 [18:27<8:32:18,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5932, 'grad_norm': 1.369865894317627, 'learning_rate': 1.2002276558019397e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 80600/91366 [27:38<8:02:15,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6272, 'grad_norm': 1.2533254623413086, 'learning_rate': 1.178337674846223e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 80800/91366 [36:47<8:00:49,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6607, 'grad_norm': 1.7352581024169922, 'learning_rate': 1.1564476938905064e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 81000/91366 [45:57<8:05:29,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7128, 'grad_norm': 1.3939071893692017, 'learning_rate': 1.1345577129347898e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 81200/91366 [55:46<7:55:25,  2.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6437, 'grad_norm': 1.634934902191162, 'learning_rate': 1.1126677319790732e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 81400/91366 [1:05:08<7:43:45,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6044, 'grad_norm': 1.3535339832305908, 'learning_rate': 1.0907777510233566e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 81600/91366 [1:14:28<7:33:05,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5926, 'grad_norm': 1.5656934976577759, 'learning_rate': 1.0688877700676402e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 81800/91366 [1:23:49<7:25:55,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.641, 'grad_norm': 1.3374749422073364, 'learning_rate': 1.0469977891119236e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 82000/91366 [1:33:16<7:28:29,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6186, 'grad_norm': 1.4941370487213135, 'learning_rate': 1.025107808156207e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 82200/91366 [1:43:24<7:24:25,  2.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.687, 'grad_norm': 1.304487943649292, 'learning_rate': 1.0032178272004903e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 82400/91366 [1:53:00<7:13:16,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6383, 'grad_norm': 1.5726165771484375, 'learning_rate': 9.813278462447737e-07, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 82600/91366 [2:02:37<7:01:06,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6089, 'grad_norm': 1.3715708255767822, 'learning_rate': 9.594378652890573e-07, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 82800/91366 [2:12:12<6:55:54,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6628, 'grad_norm': 1.4764100313186646, 'learning_rate': 9.375478843333408e-07, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 83000/91366 [2:21:50<6:45:12,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6189, 'grad_norm': 1.687374234199524, 'learning_rate': 9.156579033776242e-07, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 83200/91366 [2:31:57<6:33:06,  2.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6254, 'grad_norm': 1.6155369281768799, 'learning_rate': 8.937679224219076e-07, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 83400/91366 [2:41:34<6:19:46,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6239, 'grad_norm': 1.486980676651001, 'learning_rate': 8.718779414661909e-07, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 83600/91366 [2:51:11<6:15:31,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6357, 'grad_norm': 1.3865106105804443, 'learning_rate': 8.499879605104744e-07, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 83800/91366 [3:00:48<6:01:25,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5772, 'grad_norm': 1.5937201976776123, 'learning_rate': 8.280979795547578e-07, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 84000/91366 [3:10:24<5:55:44,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6719, 'grad_norm': 1.3160320520401, 'learning_rate': 8.062079985990413e-07, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 84200/91366 [3:20:33<5:46:36,  2.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6569, 'grad_norm': 1.6407986879348755, 'learning_rate': 7.843180176433248e-07, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 84400/91366 [3:30:11<5:36:36,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.627, 'grad_norm': 1.079128384590149, 'learning_rate': 7.624280366876082e-07, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 84600/91366 [3:39:48<5:24:44,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6153, 'grad_norm': 1.6658878326416016, 'learning_rate': 7.405380557318915e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 84800/91366 [3:49:24<5:14:19,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7049, 'grad_norm': 1.5624920129776, 'learning_rate': 7.186480747761749e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 85000/91366 [3:59:00<5:04:51,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6698, 'grad_norm': 1.0417295694351196, 'learning_rate': 6.967580938204583e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 85200/91366 [4:09:05<4:56:12,  2.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6684, 'grad_norm': 1.2860658168792725, 'learning_rate': 6.748681128647419e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 85400/91366 [4:18:42<4:49:32,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6486, 'grad_norm': 1.6418567895889282, 'learning_rate': 6.529781319090253e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 85600/91366 [4:28:19<4:38:33,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6406, 'grad_norm': 1.2053253650665283, 'learning_rate': 6.310881509533087e-07, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 85800/91366 [4:37:56<4:28:23,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6254, 'grad_norm': 1.635663390159607, 'learning_rate': 6.091981699975922e-07, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 86000/91366 [4:47:32<4:18:25,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6341, 'grad_norm': 1.610552430152893, 'learning_rate': 5.873081890418756e-07, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 86200/91366 [4:57:42<4:09:37,  2.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.633, 'grad_norm': 1.496829628944397, 'learning_rate': 5.65418208086159e-07, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 86400/91366 [5:07:21<3:58:57,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.749, 'grad_norm': 1.4909229278564453, 'learning_rate': 5.435282271304424e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 86600/91366 [5:16:58<3:49:06,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6694, 'grad_norm': 1.6730926036834717, 'learning_rate': 5.216382461747259e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 86800/91366 [5:26:34<3:39:41,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6696, 'grad_norm': 1.9060451984405518, 'learning_rate': 4.997482652190093e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 87000/91366 [5:36:10<3:30:16,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6269, 'grad_norm': 1.4555584192276, 'learning_rate': 4.778582842632927e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 87200/91366 [5:46:16<3:20:36,  2.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6387, 'grad_norm': 1.6321263313293457, 'learning_rate': 4.5596830330757615e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 87400/91366 [5:55:55<3:13:39,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.635, 'grad_norm': 1.9227468967437744, 'learning_rate': 4.340783223518596e-07, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 87600/91366 [6:05:31<3:01:02,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6246, 'grad_norm': 1.3618534803390503, 'learning_rate': 4.1218834139614297e-07, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 87800/91366 [6:15:08<2:52:51,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5836, 'grad_norm': 1.379206895828247, 'learning_rate': 3.9029836044042646e-07, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 88000/91366 [6:24:42<2:41:07,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6663, 'grad_norm': 1.9321445226669312, 'learning_rate': 3.684083794847099e-07, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 88200/91366 [6:34:52<2:29:44,  2.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6345, 'grad_norm': 1.5059466361999512, 'learning_rate': 3.465183985289933e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 88400/91366 [6:44:29<2:23:35,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6238, 'grad_norm': 0.7463447451591492, 'learning_rate': 3.2462841757327676e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 88600/91366 [6:54:07<2:13:43,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6203, 'grad_norm': 1.728411316871643, 'learning_rate': 3.0273843661756014e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 88800/91366 [7:03:43<2:03:04,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5867, 'grad_norm': 1.6074610948562622, 'learning_rate': 2.808484556618436e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 89000/91366 [7:13:20<1:52:54,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.662, 'grad_norm': 1.4596309661865234, 'learning_rate': 2.58958474706127e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 89200/91366 [7:23:28<1:44:44,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.648, 'grad_norm': 1.2075036764144897, 'learning_rate': 2.3706849375041047e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 89400/91366 [7:33:05<1:35:10,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.668, 'grad_norm': 1.3779888153076172, 'learning_rate': 2.1517851279469388e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 89600/91366 [7:42:42<1:24:55,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6368, 'grad_norm': 1.5803570747375488, 'learning_rate': 1.9328853183897732e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 89800/91366 [7:52:19<1:15:05,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.659, 'grad_norm': 1.4741765260696411, 'learning_rate': 1.7139855088326075e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 90000/91366 [8:01:55<1:05:49,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5966, 'grad_norm': 1.3723140954971313, 'learning_rate': 1.495085699275442e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 90200/91366 [8:12:06<55:09,  2.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6433, 'grad_norm': 1.2734404802322388, 'learning_rate': 1.276185889718276e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 90400/91366 [8:21:43<46:18,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6783, 'grad_norm': 1.3360705375671387, 'learning_rate': 1.0572860801611103e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 90600/91366 [8:31:20<36:59,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6005, 'grad_norm': 1.5221649408340454, 'learning_rate': 8.383862706039447e-08, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 90800/91366 [8:40:55<27:14,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6632, 'grad_norm': 1.6639751195907593, 'learning_rate': 6.194864610467789e-08, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 91000/91366 [8:50:29<17:35,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6077, 'grad_norm': 5.3683390617370605, 'learning_rate': 4.005866514896132e-08, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 91200/91366 [9:00:36<07:58,  2.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6016, 'grad_norm': 1.4305497407913208, 'learning_rate': 1.8168684193244754e-08, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91366/91366 [9:08:35<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 32915.9273, 'train_samples_per_second': 5.552, 'train_steps_per_second': 2.776, 'train_loss': 0.2038577084595285, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=91366, training_loss=0.2038577084595285, metrics={'train_runtime': 32915.9273, 'train_samples_per_second': 5.552, 'train_steps_per_second': 2.776, 'total_flos': 1.001058031632384e+18, 'train_loss': 0.2038577084595285, 'epoch': 0.9999945275347091})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()\n",
    "\n",
    "# trainer.train(resume_from_checkpoint=True)\n",
    "# checkpoint_path = \"./results/checkpoint-7000\"\n",
    "trainer.train(resume_from_checkpoint=checkpoint_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9be41bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./longt5_best_model\\\\tokenizer_config.json',\n",
       " './longt5_best_model\\\\special_tokens_map.json',\n",
       " './longt5_best_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.save_model(\"./longt5_best_model\")\n",
    "tokenizer.save_pretrained(\"./longt5_best_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a30c4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\longt5\\lib\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Summary:\n",
      " in this paper the problem of the existence of the periodicity of about 155 days during the maximum activity period for sunspot data from 1923 - 1933 ( cycle 16 ) is considered. the daily sunspot areas, the mean sunspot areas per carrington rotation, the monthly sunspot numbers and their fluctuations, which are obtained after removing the 11-year cycle are analysed. a new method of the diagnosis of an echo - effect in the power spectrum is presented. numerical results of the new method are presented.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongT5ForConditionalGeneration, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"ccdv/arxiv-summarization\")\n",
    "\n",
    "# Load fine-tuned model and tokenizer\n",
    "model = LongT5ForConditionalGeneration.from_pretrained(\"./longt5_best_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./longt5_best_model\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Prepare input\n",
    "text = dataset[\"test\"][0][\"article\"]\n",
    "input_text = \"summarize: \" + text\n",
    "inputs = tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=4096,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Move input to the same device as model\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Generate summary\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=256,\n",
    "    min_length=30,\n",
    "    length_penalty=2.0,\n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\nGenerated Summary:\\n\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d35224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:21<00:00,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average ROUGE Scores on Test Set:\n",
      "rouge1: 0.4047\n",
      "rouge2: 0.1505\n",
      "rougeL: 0.2413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongT5ForConditionalGeneration, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"ccdv/arxiv-summarization\", split=\"test\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = LongT5ForConditionalGeneration.from_pretrained(\"./longt5_best_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./longt5_best_model\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Evaluation loop\n",
    "n_samples = 100  # You can increase to 100 or full len(dataset) for full evaluation\n",
    "scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
    "\n",
    "for i in tqdm(range(n_samples), desc=\"Evaluating\"):\n",
    "    article = dataset[i][\"article\"]\n",
    "    reference = dataset[i][\"abstract\"]\n",
    "\n",
    "    input_text = \"summarize: \" + article\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=4096, truncation=True).to(device)\n",
    "\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=256,\n",
    "        min_length=30,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    predicted = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    score = scorer.score(reference, predicted)\n",
    "    for key in scores:\n",
    "        scores[key].append(score[key].fmeasure)\n",
    "\n",
    "# Average scores\n",
    "avg_scores = {key: sum(values) / len(values) for key, values in scores.items()}\n",
    "print(\"\\nAverage ROUGE Scores on Test Set:\")\n",
    "for key, value in avg_scores.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25707d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Summary:\n",
      " sunspot data from 1923 - 1933 (cycle 16) are analysed. a new method of the diagnosis of an echo-effect in the power spectrum is presented. numerical results of the new method are presented.\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge1: 0.4516\n",
      "rouge2: 0.1333\n",
      "rougeL: 0.3226\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongT5ForConditionalGeneration, AutoTokenizer\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "\n",
    "\n",
    "text_to_summarize = \"\"\"\n",
    "In this paper the problem of the existence of the periodicity of about 155 days during the maximum activity period \n",
    "for sunspot data from 1923 - 1933 (cycle 16) is considered. The daily sunspot areas, the mean sunspot areas per \n",
    "Carrington rotation, the monthly sunspot numbers and their fluctuations, which are obtained after removing the 11-year \n",
    "cycle are analysed. A new method of the diagnosis of an echo-effect in the power spectrum is presented. Numerical results \n",
    "of the new method are presented.\n",
    "\"\"\"\n",
    "\n",
    "reference_summary = \"\"\"The paper explores the periodicity of approximately 155 days in sunspot activity during 1923â€“1933, using various data and a new diagnostic method for echo effects in power spectra.\"\"\"\n",
    "\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = LongT5ForConditionalGeneration.from_pretrained(\"./longt5_best_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./longt5_best_model\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Preprocess and generate\n",
    "input_text = \"summarize: \" + text_to_summarize\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=4096, truncation=True).to(device)\n",
    "\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=256,\n",
    "    min_length=30,\n",
    "    length_penalty=2.0,\n",
    "    repetition_penalty=1.2,\n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\nGenerated Summary:\\n\", generated_summary)\n",
    "\n",
    "# Evaluate with ROUGE\n",
    "if reference_summary:\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    score = scorer.score(reference_summary, generated_summary)\n",
    "\n",
    "    print(\"\\nROUGE Scores:\")\n",
    "    for k, v in score.items():\n",
    "        print(f\"{k}: {v.fmeasure:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a09e1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ------------\n",
      "absl-py                      2.3.1\n",
      "accelerate                   0.31.0\n",
      "aiohappyeyeballs             2.6.1\n",
      "aiohttp                      3.12.15\n",
      "aiosignal                    1.4.0\n",
      "asttokens                    3.0.0\n",
      "astunparse                   1.6.3\n",
      "async-timeout                5.0.1\n",
      "attrs                        25.3.0\n",
      "certifi                      2025.7.14\n",
      "charset-normalizer           3.4.2\n",
      "click                        8.2.1\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.2\n",
      "datasets                     2.18.0\n",
      "debugpy                      1.8.14\n",
      "decorator                    5.2.1\n",
      "dill                         0.3.8\n",
      "evaluate                     0.4.1\n",
      "exceptiongroup               1.3.0\n",
      "executing                    2.2.0\n",
      "filelock                     3.18.0\n",
      "flatbuffers                  25.2.10\n",
      "frozenlist                   1.7.0\n",
      "fsspec                       2024.2.0\n",
      "gast                         0.6.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.74.0\n",
      "h5py                         3.14.0\n",
      "huggingface-hub              0.34.3\n",
      "idna                         3.10\n",
      "intel-openmp                 2021.4.0\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.37.0\n",
      "jedi                         0.19.2\n",
      "Jinja2                       3.1.6\n",
      "joblib                       1.5.1\n",
      "jupyter_client               8.6.3\n",
      "jupyter_core                 5.8.1\n",
      "keras                        3.11.0\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.8.2\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   3.0.2\n",
      "matplotlib-inline            0.1.7\n",
      "mdurl                        0.1.2\n",
      "mkl                          2021.4.0\n",
      "ml_dtypes                    0.5.3\n",
      "mpmath                       1.3.0\n",
      "multidict                    6.6.3\n",
      "multiprocess                 0.70.16\n",
      "namex                        0.1.0\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.4.2\n",
      "nltk                         3.9.1\n",
      "numpy                        1.26.4\n",
      "opt_einsum                   3.4.0\n",
      "optree                       0.17.0\n",
      "packaging                    25.0\n",
      "pandas                       2.3.1\n",
      "parso                        0.8.4\n",
      "pillow                       11.0.0\n",
      "pip                          25.1\n",
      "platformdirs                 4.3.8\n",
      "prompt_toolkit               3.0.51\n",
      "propcache                    0.3.2\n",
      "protobuf                     5.29.5\n",
      "psutil                       7.0.0\n",
      "pure_eval                    0.2.3\n",
      "pyarrow                      21.0.0\n",
      "pyarrow-hotfix               0.7\n",
      "Pygments                     2.19.1\n",
      "python-dateutil              2.9.0.post0\n",
      "pytz                         2025.2\n",
      "pywin32                      310\n",
      "PyYAML                       6.0.2\n",
      "pyzmq                        27.0.0\n",
      "regex                        2025.7.34\n",
      "requests                     2.32.4\n",
      "responses                    0.18.0\n",
      "rich                         14.1.0\n",
      "rouge_score                  0.1.2\n",
      "safetensors                  0.5.3\n",
      "setuptools                   78.1.1\n",
      "six                          1.17.0\n",
      "stack-data                   0.6.3\n",
      "sympy                        1.13.1\n",
      "tbb                          2021.13.1\n",
      "tensorboard                  2.19.0\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.19.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    3.1.0\n",
      "tokenizers                   0.19.1\n",
      "torch                        2.5.1+cu121\n",
      "torchaudio                   2.5.1+cu121\n",
      "torchvision                  0.20.1+cu121\n",
      "tornado                      6.5.1\n",
      "tqdm                         4.67.1\n",
      "traitlets                    5.14.3\n",
      "transformers                 4.41.1\n",
      "typing_extensions            4.14.0\n",
      "tzdata                       2025.2\n",
      "urllib3                      2.5.0\n",
      "wcwidth                      0.2.13\n",
      "Werkzeug                     3.1.3\n",
      "wheel                        0.45.1\n",
      "wrapt                        1.17.2\n",
      "xxhash                       3.5.0\n",
      "yarl                         1.20.1\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longt5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
